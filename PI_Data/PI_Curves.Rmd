---
title: "PI"
output: html_document
date: '2022-05-30'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
rm(list=ls()) #clears workspace 

## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools') 
library('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented') 
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix') 
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra') 
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR') 
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate') 
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron') 
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr') 
if ("tidyverse" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyverse') 


#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('tidyverse')
```

```{r}

path.p = setwd("~/Desktop/folder/CSV")
```

```{r}
# bring in the oxygen files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name (note, these are the same for this example, but I often have lots of subfolders for different Runs)
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders

#generate an empty 3 column dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names), ncol=5))
colnames(Photo.R) <- c("ID","Intercept", "umol.L.sec","Temp.C","Light_Dark") # name the columns
file.names
```

```{r}
#Load Sample Info/your respiration data file, with all the times, etc.
#Sample.Info <- read.csv(file=paste0(path.p,"/../Panama MetaData/Nubbin_Sample_Info_T0_Panama_QC.csv"), header=T) #read sample.info data
#Sample.Info <- read.csv(file=paste0(path.p,"/../metadata.csv"), header=T) #read sample.info data
Sample.Info <- read.csv(file=paste0(path.p,"/../PI.curve.metadata.final.csv"), header=T) 
View(Sample.Info)
```

```{r}
# make start and stop times real times
Sample.Info$start.time <- as.POSIXct(Sample.Info$Start.time,format="%H:%M:%S", tz = "") #convert time from character to time
Sample.Info$stop.time <- as.POSIXct(Sample.Info$Stop.Time,format="%H:%M:%S", tz = "") #convert time from character to time

```

```{r}
for(i in 1:length(file.names.full)) { # for every file in list calculate O2 uptake or release rate and add the data to the Photo.R dataframe

  #find the lines in sample info that have the same file name that is being brought in
  FRow<-which(Sample.Info$ID==strsplit(file.names[i],'.csv'))

  # read in the O2 data one by one
  Photo.Data1 <-read.csv(file.path(path.p,file.names.full[i]), skip = 1, header=T) # skips the first line
  Photo.Data1  <- Photo.Data1[,c("Time","Value","Temp")] #subset columns of interest
  Photo.Data1$Time <- as.POSIXct(Photo.Data1$Time,format="%H:%M:%S", tz = "") #convert time from character to time
  Photo.Data1 <- na.omit(Photo.Data1) #omit NA from data frame



# clean up some of the data
    n<-dim(Photo.Data1)[1] # length of full data
    Photo.Data1 <-Photo.Data1[15:(n-3),] #start at data point ~15s in to avoid excess noise from start of run and remove last 3 lines containing text

    n<-dim(Photo.Data1)[1] #list length of trimmed data
    Photo.Data1$sec <- 1:n #set seconds by one from start to finish of run in a new column
    #Save plot prior to and after data thinning to make sure thinning is not too extreme
    rename <- sub(".csv","", file.names[i]) # remove all the extra stuff in the file name

  pdf(paste0("Output_PI/",rename,"thinned.pdf")) # open the graphics device




    par(omi=rep(0.3, 4)) #set size of the outer margins in inches
    par(mfrow=c(1,2)) #set number of rows and columns in multi plot graphic

    plot(Value ~ sec, data=Photo.Data1 , xlab='Time (seconds)', ylab=expression(paste(' O'[2],' (',mu,'mol/L)')), type='n', axes=FALSE) #plot (empty plot to fill) data as a function of time

    usr  <-  par('usr') # extract the size of the figure margins

    rect(usr[1], usr[3], usr[2], usr[4], col='grey90', border=NA) # put a grey background on the plot

    whiteGrid() # make a grid
    box() # add a box around the plot

    points(Photo.Data1 $Value ~ Photo.Data1 $sec, pch=16, col=transparentColor('dodgerblue2', 0.6), cex=1.1)

    axis(1) # add the x axis
    axis(2, las=1) # add the y-axis

# Thin the data to make the code run faster
    Photo.Data.orig<-Photo.Data1 #save original unthinned data
    Photo.Data1 <-  thinData(Photo.Data1 , by=15)$newData1 #thin data by every 15 points for all the O2 values

    Photo.Data1$sec <- as.numeric(rownames(Photo.Data1 )) #maintain numeric values for time

    Photo.Data1$Temp<-NA # add a new column to fill with the thinned data

    Photo.Data1$Temp <-  thinData(Photo.Data.orig, xy = c(1,3), by=15)$newData1[,2] #thin data by every 15 points for the temp values

#plot the thinned data

  plot(Value ~ sec, data=Photo.Data1 , xlab='Time (seconds)', ylab=expression(paste(' O'[2],' (',mu,'mol/L)')), type='n', axes=FALSE)
#plot thinned data
  usr  <-  par('usr')
  rect(usr[1], usr[3], usr[2], usr[4], col='grey90', border=NA)
  whiteGrid()
  box()
  points(Photo.Data1 $Value ~ Photo.Data1 $sec, pch=16, col=transparentColor('dodgerblue2', 0.6), cex=1.1)
  axis(1)
  axis(2, las=1)
    ##Olito et al. 2017: It is running a bootstrapping technique and calculating the rate based on density
    #option to add multiple outputs method= c("z", "eq", "pc")
    Regs  <-  rankLocReg(xall=Photo.Data1$sec, yall=Photo.Data1$Value, alpha=0.5, method="pc", verbose=TRUE)
    # add the regression data
    plot(Regs)
    dev.off()

    # fill in all the O2 consumption and rate data
    Photo.R[i,2:3] <- Regs$allRegs[1,c(4,5)] #inserts slope and intercept in the dataframe
    Photo.R[i,1] <- rename #stores the file name in the Date column
    Photo.R[i,4] <- mean(Photo.Data1$Temp, na.rm=T)  #stores the Temperature in the Temp.C column
    #Photo.R[i,5] <- PR[j] #stores whether it is photosynthesis or respiration

    # rewrite the file every time... I know this is slow, but it will save the data that is already run
}

write.csv(Photo.R, 'Output_PI/Photo.R.csv')


```

```{r}
# Calculate P and R rate
Photo.R <- read.csv('~/Desktop/folder/Photo.R.csv')


#Convert sample volume to mL
Photo.R$Volume <- Photo.R$Volume/1000 #calculate volume

#Account for chamber volume to convert from umol L-1 s-1 to umol s-1. This standardizes across water volumes (different because of algae size) and removes per Liter 
Photo.R$umol.sec <- Photo.R$umol.L.sec*Photo.R$Volume

View(Photo.R)
```

```{r}
Photo.R <- Photo.R %>%
  mutate_if(sapply(., is.character), as.factor)
View(Photo.R)
```

```{r}
Photo.R <- read.csv('~/Desktop/folder/PI_curvesRates.csv')
View(Photo.R)
```

```{r}
PhotoMeans<- Photo.R %>%
  group_by(species, run)%>%
  summarise(rates.mean = mean(umol.sec.corr.pos), se = sd(umol.sec.corr.pos)/sqrt(n()))
```

```{r}
# plot the raw data with the means on top
plot <- ggplot()+
  theme_bw()+  
  #geom_point(data=Photo.R, aes(x=run, y=umol.cm2.hr, alpha = 0.05), position = position_dodge(width = 0.2), size=4)+
  geom_point(data=PhotoMeans, aes(x=run, y=rates.mean),  size=1)+
  geom_line(data = PhotoMeans,  aes(x=run, y=rates.mean), size=1)+
  geom_errorbar(data = PhotoMeans, aes(x = run, ymin=rates.mean-se, ymax=rates.mean+se, width=.2))
  #facet_wrap(~ Species, labeller = labeller(.multi_line = FALSE))+
  ggsave('Output/RespirationRates.pdf')
  
  
  plot
  
```

```{r}
PAR <- as.numeric(Photo.R$run)
View(Photo.R)

Pc <- as.numeric(Photo.R$umol.sec.corr.pos) 

plot(PAR,Pc,xlab="",
       ylab="",
       xlim=c(0,max(PAR)),
       ylim=c(-1,1.2),
       cex.lab=0.8,cex.axis=0.8,cex=1, main="",
       adj=0.05) 

#set plot info
  
  mtext(expression("Photon Flux Density ("*mu*"mol photons "*m^-2*s^-1*")"),side=1,line=3.3,cex=1)
  
  #add labels
  
  mtext(expression(Rate* " ("*mu*"mol"*~O[2]*" "*cm^-2 *~h^-1*")"),side=2,line=2,cex=1)
  
  #add labels
```

```{r}
  #fit a model using a Nonlinear Least Squares regression of a non-rectangular hyperbola (Marshall & Biscoe, 1980)

  curve.nlslrc= nls(Pc ~ (1/(2*theta))*(AQY*PAR+Am-sqrt((AQY*PAR+Am)^2-4*AQY*theta*Am*PAR))-Rd,start=list(Am=(max(Pc)-min(Pc)),AQY=0.001,Rd=-min(Pc),theta=0.8)) 
  
  my.fit <- summary(curve.nlslrc)
  #summary of model fit
  
```

```{r}
#draw the curve using the model fit
  #hyperbolic tangent, more common way to fit 
  
  mor.curve.fitting<- curve((1/(2*summary(curve.nlslrc)$coef[4,1]))*(summary(curve.nlslrc)$coef[2,1]*x+summary(curve.nlslrc)$coef[1,1]-sqrt((summary(curve.nlslrc)$coef[2,1]*x+summary(curve.nlslrc)$coef[1,1])^2-4*summary(curve.nlslrc)$coef[2,1]*summary(curve.nlslrc)$coef[4,1]*summary(curve.nlslrc)$coef[1,1]*x))-summary(curve.nlslrc)$coef[3,1],lwd=2,col="blue",add=T)
  
  
```